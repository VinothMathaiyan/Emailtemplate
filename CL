import pandas as pd

def process_training_data(file_name, eligibility_threshold, output_file):
    # Load your data
    df = pd.read_csv(file_name)

    # Consolidate records by counting trainings per ID
    df['Trainings_Count'] = df.groupby('ID')['Training'].transform('count')

    # Filter eligible IDs
    eligible_ids = df[df['Trainings_Count'] >= eligibility_threshold]['ID'].unique()

    # Filter the DataFrame for eligible records
    df_eligible = df[df['ID'].isin(eligible_ids)]

    # Calculate weight per region
    region_weights = df_eligible['Region'].value_counts(normalize=True)

    # Sample 5000 records proportionally
    sampled_df = df_eligible.groupby('Region').apply(lambda x: x.sample(int(5000 * region_weights.loc[x.name])))

    # Save the sampled data to an Excel file
    sampled_df.to_excel(output_file, index=False)

    return sampled_df

# Example usage
file_name = 'your_file.csv'
eligibility_threshold = 10  # This can be an input parameter
output_file = 'sampled_data.xlsx'  # Output file name
sampled_data = process_training_data(file_name, eligibility_threshold, output_file)
print(sampled_data)
