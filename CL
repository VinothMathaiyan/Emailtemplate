import pandas as pd
import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Load the Excel file
file_path = "File1.xlsx"
xls = pd.ExcelFile(file_path)

# Read free-text responses from sheets 1234 and 5678
df_1234 = pd.read_excel(xls, sheet_name="1234")
df_5678 = pd.read_excel(xls, sheet_name="5678")

# Read topics/moments from Stages sheet
df_stages = pd.read_excel(xls, sheet_name="Stages")

# Read custom stopwords from stopwords sheet
stopwords_list = pd.read_excel(xls, sheet_name="stopwords").iloc[:, 0].tolist()

# Ensure necessary columns exist
response_col = "Response"  # Change if column name differs
if response_col not in df_1234.columns or response_col not in df_5678.columns:
    raise ValueError(f"Column '{response_col}' not found in response sheets.")

# Preprocess text (TF-IDF vectorization)
vectorizer = TfidfVectorizer(stop_words=stopwords_list)
stages_tfidf = vectorizer.fit_transform(df_stages.iloc[:, 0])  # Assuming first column has topics

def map_topics(df):
    """Maps relevant stages to each response based on cosine similarity."""
    df["Stages"] = ""  # Initialize new column
    responses_tfidf = vectorizer.transform(df[response_col].astype(str))  # Transform responses
    similarity_matrix = cosine_similarity(responses_tfidf, stages_tfidf)  # Compute similarity

    # Assign topics based on highest similarity
    for i, similarities in enumerate(similarity_matrix):
        best_matches = [df_stages.iloc[j, 0] for j in range(len(similarities)) if similarities[j] > 0.1]
        df.at[i, "Stages"] = "; ".join(best_matches) if best_matches else "No Match"

# Map topics for both sheets
map_topics(df_1234)
map_topics(df_5678)

# Save results
with pd.ExcelWriter(file_path, engine="openpyxl", mode="a", if_sheet_exists="replace") as writer:
    df_1234.to_excel(writer, sheet_name="1234", index=False)
    df_5678.to_excel(writer, sheet_name="5678", index=False)

print("Mapping completed and saved to File1.xlsx")

