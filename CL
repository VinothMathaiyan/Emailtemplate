import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import string
import nltk

nltk.download('stopwords')
nltk.download('punkt')

def preprocess_text(text):
    stop_words = set(stopwords.words('english'))
    words = word_tokenize(text.lower())
    words = [word for word in words if word.isalnum() and word not in stop_words and word not in string.punctuation]
    return ' '.join(words)

# Read the Excel File
df = pd.read_excel('your_file.xlsx')
df['cleaned_responses'] = df['Response'].apply(preprocess_text)

# Group by Topics and Actor
grouped = df.groupby(['Topics', 'Actor'])

# Function to Cluster Responses
def cluster_responses(group, num_clusters=5):
    vectorizer = TfidfVectorizer(max_features=1000)
    X = vectorizer.fit_transform(group['cleaned_responses'])
    
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    kmeans.fit(X)
    
    group['cluster'] = kmeans.labels_
    return group, kmeans, vectorizer

# Apply Clustering for Each Group
clusters = {}
for (topic, actor), group in grouped:
    clustered_group, kmeans, vectorizer = cluster_responses(group)
    clusters[(topic, actor)] = (clustered_group, kmeans, vectorizer)

# Interpret Clusters
def get_top_words_per_cluster(kmeans, vectorizer, n_words=10):
    order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]
    terms = vectorizer.get_feature_names_out()
    
    clusters = {}
    for i in range(kmeans.n_clusters):
        clusters[i] = [terms[ind] for ind in order_centroids[i, :n_words]]
    return clusters

# Display Top Words for Each Cluster
all_top_words = {}
for key, (group, kmeans, vectorizer) in clusters.items():
    top_words_per_cluster = get_top_words_per_cluster(kmeans, vectorizer)
    all_top_words[key] = top_words_per_cluster
    
    print(f"Topic: {key[0]}, Actor: {key[1]}")
    for cluster_id, top_words in top_words_per_cluster.items():
        print(f"  Cluster {cluster_id} Top Words: {', '.join(top_words)}")
