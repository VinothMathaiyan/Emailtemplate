import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Sample DataFrame: Replace with your actual data
data = {
    'Topics': ['Topic1', 'Topic1', 'Topic2', 'Topic2', 'Topic1'],
    'Actor': ['Actor1', 'Actor1', 'Actor2', 'Actor2', 'Actor1'],
    'cleaned_responses1': [
        'I love coding in Python.',
        'Python is great for data analysis.',
        'I enjoy machine learning and AI.',
        'Data science is an exciting field.',
        'Machine learning models are fascinating.'
    ]
}

df = pd.DataFrame(data)

# Step 1: Group by Topics and Actor
grouped = df.groupby(['Topics', 'Actor'])

# Function to perform clustering on responses and return the optimal number of clusters
def optimal_clusters(responses, max_k=10):
    vectorizer = TfidfVectorizer(stop_words='english')
    X = vectorizer.fit_transform(responses)
    
    best_k = 2
    best_score = -1
    
    for k in range(2, max_k + 1):
        model = KMeans(n_clusters=k, random_state=42)
        labels = model.fit_predict(X)
        score = silhouette_score(X, labels)
        
        if score > best_score:
            best_k = k
            best_score = score
    
    model = KMeans(n_clusters=best_k, random_state=42)
    labels = model.fit_predict(X)
    return labels, best_k, best_score

# Step 2: Apply clustering within each group and find optimal number of clusters
def cluster_with_optimal_k(group):
    labels, best_k, best_score = optimal_clusters(group['cleaned_responses1'].tolist())
    group['Cluster'] = labels
    group['Optimal_Clusters'] = best_k
    group['Silhouette_Score'] = best_score
    return group

df = grouped.apply(cluster_with_optimal_k)
print(df)
